import os
import platform
import shutil
import subprocess
from pathlib import Path


PROJECT_DIR = Path.cwd()
ENABLE_MLFLOW = "{{ cookiecutter.enable_mlflow_tracking }}".lower().startswith("y")
INSTALL_DEPS = "{{ cookiecutter.install_dependencies }}".lower().startswith("y")
USE_CUDA = "{{ cookiecutter.use_cuda_default }}".lower().startswith("y")


def remove_mlflow_assets() -> None:
    if ENABLE_MLFLOW:
        return
    shutil.rmtree(PROJECT_DIR / "mlflow", ignore_errors=True)
    mlflow_doc = PROJECT_DIR / "docs" / "mlflow.md"
    if mlflow_doc.exists():
        mlflow_doc.unlink()


def maybe_install_dependencies() -> None:
    if not INSTALL_DEPS:
        print("Skipping automatic uv install (per Cookiecutter prompt).")
        return

    try:
        subprocess.run(
            ["uv", "sync", "--extra", "dev"],
            check=True,
        )
    except (OSError, subprocess.CalledProcessError) as exc:
        print(f"âš ï¸  uv sync failed: {exc}. Install dependencies manually with `uv sync`.")


def init_git_repo() -> None:
    git_dir = PROJECT_DIR / ".git"
    if git_dir.exists():
        return
    try:
        subprocess.run(["git", "init"], check=True)
    except (OSError, subprocess.CalledProcessError):
        print("âš ï¸  Unable to run `git init`. Initialize git manually.")


def warn_on_cuda_on_arm() -> None:
    if not USE_CUDA:
        return
    if platform.machine().lower() == "arm64":
        print(
            "âš ï¸  CUDA base images rarely run natively on Apple Silicon. "
            "Use docker/Dockerfile.cpu or build with --platform=linux/amd64."
        )


def print_success_message() -> None:
    """Display success message after project generation."""
    project_name = "{{ cookiecutter.project_name }}"
    
    success = f"""
    â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
    â•‘                                                           â•‘
    â•‘              âœ… Project Generated Successfully!           â•‘
    â•‘                                                           â•‘
    â•‘              Project: {project_name:<30} â•‘
    â•‘                                                           â•‘
    â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

    ğŸ‰ Congratulations! Your PyTorch Computer Vision project is ready.

    ğŸ“ Project Structure:
      â€¢ Source code: src/{{ cookiecutter.python_package }}/
      â€¢ Training scripts: scripts/train.py
      â€¢ Deployment: scripts/serve.py
      â€¢ Configuration: configs/
      â€¢ Docker files: docker/
      â€¢ Tests: tests/

    ğŸš€ Quick Start:
      1. Review README.md for detailed documentation
      2. Configure your datasets in configs/training.yaml
      3. Set up remote repository (see docs/remote_repo.md)
      4. Start training: uv run train_model --help

    ğŸ“š Documentation:
      â€¢ Docker setup: docs/docker.md
      â€¢ MLflow tracking: docs/mlflow.md
      â€¢ Remote repo: docs/remote_repo.md

    ğŸ’¡ Next Steps:
      1. Review README.md for environment & Docker instructions
      2. Configure remotes via docs/remote_repo.md
      3. Update configs/training.yaml with your datasets
      4. Run tests: uv run pytest
      5. Start developing! ğŸš€

    Happy coding! ğŸŠ
    """
    print(success)


def main() -> None:
    print("\nğŸ”§ Setting up your project...\n")
    
    print("ğŸ“¦ Removing MLflow assets (if disabled)...")
    remove_mlflow_assets()
    
    print("ğŸ“‚ Initializing Git repository...")
    init_git_repo()
    
    warn_on_cuda_on_arm()
    
    print("ğŸ“¥ Installing dependencies...")
    maybe_install_dependencies()
    
    print("\nâœ¨ Finalizing setup...\n")
    print_success_message()


if __name__ == "__main__":
    main()

