{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Model Experiment\n",
        "\n",
        "This notebook contains experiments for training and evaluating models.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Import standard libraries\n",
        "import sys\n",
        "from pathlib import Path\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import matplotlib.pyplot as plt\n",
        "{% if cookiecutter.enable_mlflow_tracking == 'y' or cookiecutter.enable_mlflow_tracking == 'yes' %}\n",
        "import mlflow\n",
        "import mlflow.pytorch\n",
        "{% endif %}\n",
        "\n",
        "# Set up paths\n",
        "project_root = Path().resolve().parent.parent.parent\n",
        "sys.path.insert(0, str(project_root))\n",
        "\n",
        "# Data paths\n",
        "data_dir = project_root / \"science\" / \"data\"\n",
        "raw_data_dir = data_dir / \"raw\"\n",
        "processed_data_dir = data_dir / \"processed\"\n",
        "interim_data_dir = data_dir / \"interim\"\n",
        "external_data_dir = data_dir / \"external\"\n",
        "output_data_dir = data_dir / \"output\"\n",
        "\n",
        "# Models path\n",
        "models_dir = project_root / \"science\" / \"models\"\n",
        "models_dir.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "# Import project package\n",
        "from {{ cookiecutter.python_package }}.vision import load_image, preprocess_image, predict_simple\n",
        "from {{ cookiecutter.python_package }}.utils import load_state, save_state\n",
        "\n",
        "{% if cookiecutter.enable_mlflow_tracking == 'y' or cookiecutter.enable_mlflow_tracking == 'yes' %}\n",
        "# MLflow setup\n",
        "mlflow.set_tracking_uri(\"{{ cookiecutter.mlflow_backend_store }}\")\n",
        "mlflow.set_experiment(\"{{ cookiecutter.project_name }}\")\n",
        "{% endif %}\n",
        "\n",
        "print(f\"Project root: {project_root}\")\n",
        "print(f\"Processed data directory: {processed_data_dir}\")\n",
        "print(f\"Models directory: {models_dir}\")\n",
        "print(f\"Device: {'cuda' if torch.cuda.is_available() else 'cpu'}\")\n",
        "{% if cookiecutter.enable_mlflow_tracking == 'y' or cookiecutter.enable_mlflow_tracking == 'yes' %}\n",
        "print(f\"MLflow tracking URI: {mlflow.get_tracking_uri()}\")\n",
        "{% endif %}\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Load Processed Data\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Example: Load processed data\n",
        "# Modify based on your data format\n",
        "\n",
        "# if processed_data_dir.exists():\n",
        "#     # Load your processed data here\n",
        "#     # For example, if you have numpy arrays:\n",
        "#     # data = np.load(processed_data_dir / \"train_data.npy\")\n",
        "#     # labels = np.load(processed_data_dir / \"train_labels.npy\")\n",
        "#     print(\"Load your processed data here\")\n",
        "# else:\n",
        "#     print(f\"Processed data directory does not exist: {processed_data_dir}\")\n",
        "#     print(\"Please process your raw data first\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Define Model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Example: Define a simple model\n",
        "# Replace with your actual model architecture\n",
        "\n",
        "# class SimpleModel(nn.Module):\n",
        "#     def __init__(self, num_classes=10):\n",
        "#         super().__init__()\n",
        "#         self.conv1 = nn.Conv2d(3, 32, kernel_size=3, padding=1)\n",
        "#         self.conv2 = nn.Conv2d(32, 64, kernel_size=3, padding=1)\n",
        "#         self.pool = nn.AdaptiveAvgPool2d(1)\n",
        "#         self.fc = nn.Linear(64, num_classes)\n",
        "#     \n",
        "#     def forward(self, x):\n",
        "#         x = torch.relu(self.conv1(x))\n",
        "#         x = torch.relu(self.conv2(x))\n",
        "#         x = self.pool(x)\n",
        "#         x = x.view(x.size(0), -1)\n",
        "#         x = self.fc(x)\n",
        "#         return x\n",
        "\n",
        "# model = SimpleModel(num_classes=10)\n",
        "# device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "# model = model.to(device)\n",
        "# print(f\"Model created and moved to {device}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Training Loop with MLflow Tracking\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Example: Training loop with MLflow tracking\n",
        "# Uncomment and modify based on your needs\n",
        "\n",
        "{% if cookiecutter.enable_mlflow_tracking == 'y' or cookiecutter.enable_mlflow_tracking == 'yes' %}\n",
        "# Start MLflow run\n",
        "with mlflow.start_run(run_name=\"model_experiment\") as run:\n",
        "    # Log hyperparameters\n",
        "    num_epochs = 10\n",
        "    learning_rate = 0.001\n",
        "    batch_size = 32\n",
        "    \n",
        "    mlflow.log_params({\n",
        "        \"num_epochs\": num_epochs,\n",
        "        \"learning_rate\": learning_rate,\n",
        "        \"batch_size\": batch_size,\n",
        "        \"optimizer\": \"Adam\",\n",
        "        \"device\": str(device),\n",
        "    })\n",
        "    \n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
        "    \n",
        "    train_losses = []\n",
        "    val_losses = []\n",
        "    train_accs = []\n",
        "    val_accs = []\n",
        "    \n",
        "    for epoch in range(num_epochs):\n",
        "        model.train()\n",
        "        epoch_loss = 0.0\n",
        "        correct = 0\n",
        "        total = 0\n",
        "        \n",
        "        # Your training loop here\n",
        "        # for batch_idx, (data, target) in enumerate(train_loader):\n",
        "        #     data, target = data.to(device), target.to(device)\n",
        "        #     optimizer.zero_grad()\n",
        "        #     output = model(data)\n",
        "        #     loss = criterion(output, target)\n",
        "        #     loss.backward()\n",
        "        #     optimizer.step()\n",
        "        #     epoch_loss += loss.item()\n",
        "        #     \n",
        "        #     # Calculate accuracy\n",
        "        #     _, predicted = torch.max(output.data, 1)\n",
        "        #     total += target.size(0)\n",
        "        #     correct += (predicted == target).sum().item()\n",
        "        \n",
        "        avg_loss = epoch_loss / len(train_loader) if len(train_loader) > 0 else 0.0\n",
        "        accuracy = 100 * correct / total if total > 0 else 0.0\n",
        "        train_losses.append(avg_loss)\n",
        "        train_accs.append(accuracy)\n",
        "        \n",
        "        # Log metrics for each epoch\n",
        "        mlflow.log_metrics({\n",
        "            \"train_loss\": avg_loss,\n",
        "            \"train_accuracy\": accuracy,\n",
        "        }, step=epoch)\n",
        "        \n",
        "        print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {avg_loss:.4f}, Accuracy: {accuracy:.2f}%\")\n",
        "        \n",
        "        # Validation loop (if you have validation data)\n",
        "        # model.eval()\n",
        "        # val_loss = 0.0\n",
        "        # val_correct = 0\n",
        "        # val_total = 0\n",
        "        # with torch.no_grad():\n",
        "        #     for data, target in val_loader:\n",
        "        #         data, target = data.to(device), target.to(device)\n",
        "        #         output = model(data)\n",
        "        #         val_loss += criterion(output, target).item()\n",
        "        #         _, predicted = torch.max(output.data, 1)\n",
        "        #         val_total += target.size(0)\n",
        "        #         val_correct += (predicted == target).sum().item()\n",
        "        # \n",
        "        # val_avg_loss = val_loss / len(val_loader)\n",
        "        # val_accuracy = 100 * val_correct / val_total\n",
        "        # val_losses.append(val_avg_loss)\n",
        "        # val_accs.append(val_accuracy)\n",
        "        # \n",
        "        # mlflow.log_metrics({\n",
        "        #     \"val_loss\": val_avg_loss,\n",
        "        #     \"val_accuracy\": val_accuracy,\n",
        "        # }, step=epoch)\n",
        "    \n",
        "    # Log final metrics\n",
        "    mlflow.log_metrics({\n",
        "        \"final_train_loss\": train_losses[-1] if train_losses else 0.0,\n",
        "        \"final_train_accuracy\": train_accs[-1] if train_accs else 0.0,\n",
        "    })\n",
        "    \n",
        "    # Log model\n",
        "    mlflow.pytorch.log_model(model, \"model\")\n",
        "    \n",
        "    print(f\"MLflow run ID: {run.info.run_id}\")\n",
        "    print(f\"View run at: {mlflow.get_tracking_uri()}\")\n",
        "{% else %}\n",
        "# Training loop without MLflow\n",
        "# num_epochs = 10\n",
        "# learning_rate = 0.001\n",
        "# \n",
        "# criterion = nn.CrossEntropyLoss()\n",
        "# optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
        "# \n",
        "# train_losses = []\n",
        "# \n",
        "# for epoch in range(num_epochs):\n",
        "#     model.train()\n",
        "#     epoch_loss = 0.0\n",
        "#     \n",
        "#     # Your training loop here\n",
        "#     # for batch_idx, (data, target) in enumerate(train_loader):\n",
        "#     #     data, target = data.to(device), target.to(device)\n",
        "#     #     optimizer.zero_grad()\n",
        "#     #     output = model(data)\n",
        "#     #     loss = criterion(output, target)\n",
        "#     #     loss.backward()\n",
        "#     #     optimizer.step()\n",
        "#     #     epoch_loss += loss.item()\n",
        "#     \n",
        "#     avg_loss = epoch_loss / len(train_loader) if len(train_loader) > 0 else 0.0\n",
        "#     train_losses.append(avg_loss)\n",
        "#     print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {avg_loss:.4f}\")\n",
        "{% endif %}\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Save Model and Log to MLflow\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Example: Save model checkpoint\n",
        "# Uncomment when ready to save\n",
        "\n",
        "# checkpoint = {\n",
        "#     'model_state_dict': model.state_dict(),\n",
        "#     'optimizer_state_dict': optimizer.state_dict(),\n",
        "#     'epoch': num_epochs,\n",
        "#     'loss': train_losses[-1] if train_losses else 0.0,\n",
        "# }\n",
        "# \n",
        "# checkpoint_path = save_state(\n",
        "#     checkpoint,\n",
        "#     models_dir,\n",
        "#     prefix=\"model_experiment\"\n",
        "# )\n",
        "# print(f\"Model saved to: {checkpoint_path}\")\n",
        "# \n",
        "{% if cookiecutter.enable_mlflow_tracking == 'y' or cookiecutter.enable_mlflow_tracking == 'yes' %}\n",
        "# Log checkpoint as artifact to MLflow\n",
        "# mlflow.log_artifact(str(checkpoint_path), \"checkpoints\")\n",
        "# print(f\"Checkpoint logged to MLflow: {checkpoint_path.name}\")\n",
        "{% endif %}\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Load Saved Model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Example: Load a saved model checkpoint\n",
        "# Uncomment when you have a saved model\n",
        "\n",
        "# if models_dir.exists():\n",
        "#     checkpoint_files = list(models_dir.glob(\"*.pt\"))\n",
        "#     if checkpoint_files:\n",
        "#         # Load the most recent checkpoint\n",
        "#         latest_checkpoint = max(checkpoint_files, key=lambda p: p.stat().st_mtime)\n",
        "#         print(f\"Loading checkpoint: {latest_checkpoint}\")\n",
        "#         \n",
        "#         checkpoint = load_state(latest_checkpoint)\n",
        "#         model.load_state_dict(checkpoint['model_state_dict'])\n",
        "#         print(f\"Model loaded from epoch {checkpoint.get('epoch', 'unknown')}\")\n",
        "#     else:\n",
        "#         print(\"No checkpoint files found in models directory\")\n",
        "# else:\n",
        "#     print(\"Models directory does not exist\")\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
